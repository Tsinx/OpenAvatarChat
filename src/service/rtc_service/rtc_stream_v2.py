import asyncio
import json
import uuid
import weakref
from typing import Optional, Dict

import numpy as np
# noinspection PyPackageRequirements
from fastrtc import AsyncAudioVideoStreamHandler, AudioEmitType, VideoEmitType
from loguru import logger

from chat_engine.common.client_handler_base import ClientHandlerDelegate, ClientSessionDelegate
from chat_engine.common.engine_channel_type import EngineChannelType
from chat_engine.data_models.chat_data.chat_data_model import ChatData
from chat_engine.data_models.chat_data_type import ChatDataType
from chat_engine.data_models.chat_signal import ChatSignal
from chat_engine.data_models.chat_signal_type import ChatSignalType, ChatSignalSourceType
from engine_utils.interval_counter import IntervalCounter
from aiortc.codecs import vpx 
vpx.DEFAULT_BITRATE = 5000000
vpx.MIN_BITRATE = 1000000
vpx.MAX_BITRATE = 10000000


class RtcStreamV2(AsyncAudioVideoStreamHandler):
    """æ”¯æŒæ‰‹åŠ¨å½•éŸ³æ§åˆ¶çš„RTCæµå¤„ç†å™¨"""
    
    def __init__(self,
                 session_id: Optional[str],
                 expected_layout="mono",
                 input_sample_rate=16000,
                 output_sample_rate=24000,
                 output_frame_size=480,
                 fps=30,
                 stream_start_delay = 0.5,
                 ):
        super().__init__(
            expected_layout=expected_layout,
            input_sample_rate=input_sample_rate,
            output_sample_rate=output_sample_rate,
            output_frame_size=output_frame_size,
            fps=fps
        )
        self.client_handler_delegate: Optional[ClientHandlerDelegate] = None
        self.client_session_delegate: Optional[ClientSessionDelegate] = None

        self.weak_factory: Optional[weakref.ReferenceType[RtcStreamV2]] = None

        self.session_id = session_id
        self.stream_start_delay = stream_start_delay

        self.chat_channel = None
        self.first_audio_emitted = False

        self.quit = asyncio.Event()
        self.last_frame_time = 0

        self.emit_counter = IntervalCounter("emit counter")

        self.start_time = None
        self.timestamp_base = self.input_sample_rate

        self.streams: Dict[str, RtcStreamV2] = {}
        
        # æ‰‹åŠ¨å½•éŸ³æ§åˆ¶çŠ¶æ€
        self.is_recording = False
        self.recording_start_time = None

    # copy is used as create_instance in fastrtc
    def copy(self, **kwargs) -> AsyncAudioVideoStreamHandler:
        try:
            if self.client_handler_delegate is None:
                raise Exception("ClientHandlerDelegate is not set.")
            session_id = kwargs.get("webrtc_id", None)
            if session_id is None:
                session_id = uuid.uuid4().hex
            new_stream = RtcStreamV2(
                session_id,
                expected_layout=self.expected_layout,
                input_sample_rate=self.input_sample_rate,
                output_sample_rate=self.output_sample_rate,
                output_frame_size=self.output_frame_size,
                fps=self.fps,
                stream_start_delay=self.stream_start_delay,
            )
            new_stream.weak_factory = weakref.ref(self)
            new_session_delegate = self.client_handler_delegate.start_session(
                session_id=session_id,
                timestamp_base=self.input_sample_rate,
            )
            new_stream.client_session_delegate = new_session_delegate
            if session_id in self.streams:
                msg = f"Stream {session_id} already exists."
                raise RuntimeError(msg)
            self.streams[session_id] = new_stream
            return new_stream
        except Exception as e:
            logger.opt(exception=True).error(f"Failed to create stream: {e}")
            raise

    async def emit(self) -> AudioEmitType:
        try:
            if not self.first_audio_emitted:
                self.client_session_delegate.clear_data()
                self.first_audio_emitted = True

            while not self.quit.is_set():
                chat_data = await self.client_session_delegate.get_data(EngineChannelType.AUDIO)
                if chat_data is None or chat_data.data is None:
                    continue
                audio_array = chat_data.data.get_main_data()
                if audio_array is None:
                    continue
                sample_num = audio_array.shape[-1]
                self.emit_counter.add_property("emit_audio", sample_num / self.output_sample_rate)
                return self.output_sample_rate, audio_array
        except Exception as e:
            logger.opt(exception=e).error(f"Error in emit: ")
            raise

    async def video_emit(self) -> VideoEmitType:
        try:
            if not self.first_audio_emitted:
                await asyncio.sleep(0.1)
            self.emit_counter.add_property("emit_video")
            while not self.quit.is_set():
                video_frame_data: ChatData = await self.client_session_delegate.get_data(EngineChannelType.VIDEO)
                if video_frame_data is None or video_frame_data.data is None:
                    continue
                frame_data = video_frame_data.data.get_main_data().squeeze()
                if frame_data is None:
                    continue
                return frame_data
        except Exception as e:
            logger.opt(exception=e).error(f"Error in video_emit: ")
            raise

    async def receive(self, frame: tuple[int, np.ndarray]):
        """æ¥æ”¶éŸ³é¢‘æ•°æ®ï¼Œæ”¯æŒæ‰‹åŠ¨å½•éŸ³æ§åˆ¶"""
        if self.client_session_delegate is None:
            return
        timestamp = self.client_session_delegate.get_timestamp()
        if timestamp[0] / timestamp[1] < self.stream_start_delay:
            return
        _, array = frame
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å½•éŸ³æ§åˆ¶ä¿¡å·
        recording_signal = getattr(frame, 'recording_signal', None)
        
        # åˆ›å»ºæ•°æ®åŒ…å¹¶æ·»åŠ å½•éŸ³æ§åˆ¶å…ƒæ•°æ®
        data_bundle = self.client_session_delegate.input_data_definitions[EngineChannelType.AUDIO]
        if recording_signal:
            data_bundle.add_meta('recording_signal', recording_signal)
        
        self.client_session_delegate.put_data(
            EngineChannelType.AUDIO,
            array,
            timestamp,
            self.input_sample_rate,
        )

    async def video_receive(self, frame):
        if self.client_session_delegate is None:
            return
        timestamp = self.client_session_delegate.get_timestamp()
        if timestamp[0] / timestamp[1] < self.stream_start_delay:
            return
        self.client_session_delegate.put_data(
            EngineChannelType.VIDEO,
            frame,
            timestamp,
            self.fps,
        )

    def set_channel(self, channel):
        super().set_channel(channel)
        self.chat_channel = channel
        
        async def process_chat_history():
            role = None
            chat_id = None
            while not self.quit.is_set():
                chat_data = await self.client_session_delegate.get_data(EngineChannelType.TEXT)
                if chat_data is None or chat_data.data is None:
                    continue
                logger.debug(f"Got chat data {str(chat_data)}")
                current_role = 'human' if chat_data.type == ChatDataType.HUMAN_TEXT else 'avatar'
                chat_id = uuid.uuid4().hex if current_role != role else chat_id
                role = current_role
                self.chat_channel.send(json.dumps({'type': 'chat', 'message': chat_data.data.get_main_data(), 
                                                    'id': chat_id, 'role': current_role}))  
        asyncio.create_task(process_chat_history())
            
        @channel.on("message")
        def _(message):
            logger.info(f"Received message Custom: {message}")
            try:
                message = json.loads(message)
            except Exception as e:
                logger.info(e)
                message = {}

            if self.client_session_delegate is None:
                return
            timestamp = self.client_session_delegate.get_timestamp()
            if timestamp[0] / timestamp[1] < self.stream_start_delay:
                return
            logger.info(f'on_chat_datachannel: {message}')

            if message['type'] == 'stop_chat':
                self.client_session_delegate.emit_signal(
                    ChatSignal(
                        signal_type=ChatSignalType.STOP_CHAT,
                        source_type=ChatSignalSourceType.CLIENT,
                        source_id=self.session_id,
                        target_id=self.session_id,
                        data={}
                    )
                )
            elif message['type'] == 'recording_control':
                # å¤„ç†å½•éŸ³æ§åˆ¶ä¿¡å·
                logger.info(f"ğŸ¤ [Backend] æ¥æ”¶åˆ°å½•éŸ³æ§åˆ¶ä¿¡å·: {message}")
                control_action = message.get('action')
                duration = message.get('duration', 'N/A')
                
                if control_action == 'start':
                    logger.info(f"ğŸ¤ [Backend] å¼€å§‹æ‰‹åŠ¨å½•éŸ³ - session_id: {self.session_id}")
                    self.is_recording = True
                    self.recording_start_time = timestamp[0]
                    logger.info(f"ğŸ¤ [Backend] å½•éŸ³çŠ¶æ€å·²è®¾ç½®: is_recording={self.is_recording}, start_time={self.recording_start_time}")
                elif control_action == 'stop':
                    logger.info(f"ğŸ¤ [Backend] åœæ­¢æ‰‹åŠ¨å½•éŸ³ - session_id: {self.session_id}, å‰ç«¯æŠ¥å‘Šæ—¶é•¿: {duration}ms")
                    if self.is_recording:
                        actual_duration = timestamp[0] - self.recording_start_time if self.recording_start_time else 0
                        logger.info(f"ğŸ¤ [Backend] åç«¯è®¡ç®—çš„å®é™…å½•éŸ³æ—¶é•¿: {actual_duration}ms")
                    else:
                        logger.warning(f"ğŸ¤ [Backend] è­¦å‘Š: æ”¶åˆ°åœæ­¢ä¿¡å·ä½†å½“å‰æœªåœ¨å½•éŸ³çŠ¶æ€")
                    
                    self.is_recording = False
                    self.recording_start_time = None
                    logger.info(f"ğŸ¤ [Backend] å½•éŸ³çŠ¶æ€å·²é‡ç½®: is_recording={self.is_recording}, start_time={self.recording_start_time}")
                else:
                    logger.warning(f"ğŸ¤ [Backend] æœªçŸ¥çš„å½•éŸ³æ§åˆ¶åŠ¨ä½œ: {control_action}")

    def close(self):
        logger.info(f"ğŸ”Œ [Stream] å¼€å§‹å…³é—­RTCæµ - session_id: {self.session_id}")
        
        # è®¾ç½®é€€å‡ºä¿¡å·
        logger.info(f"ğŸ”Œ [Stream] è®¾ç½®é€€å‡ºä¿¡å· - session_id: {self.session_id}")
        self.quit.set()
        logger.info(f"ğŸ”Œ [Stream] é€€å‡ºä¿¡å·å·²è®¾ç½® - session_id: {self.session_id}")
        
        # ä»æµå­—å…¸ä¸­ç§»é™¤å½“å‰ä¼šè¯
        if self.session_id in self.streams:
            logger.info(f"ğŸ”Œ [Stream] ä»æµå­—å…¸ä¸­ç§»é™¤ä¼šè¯ - session_id: {self.session_id}")
            logger.info(f"ğŸ”Œ [Stream] ç§»é™¤å‰æµå­—å…¸å¤§å°: {len(self.streams)}")
            del self.streams[self.session_id]
            logger.info(f"ğŸ”Œ [Stream] ç§»é™¤åæµå­—å…¸å¤§å°: {len(self.streams)}")
        else:
            logger.warning(f"âš ï¸ [Stream] è­¦å‘Š: ä¼šè¯ä¸åœ¨æµå­—å…¸ä¸­ - session_id: {self.session_id}")
        
        # è°ƒç”¨çˆ¶ç±»çš„closeæ–¹æ³•
        logger.info(f"ğŸ”Œ [Stream] è°ƒç”¨çˆ¶ç±»closeæ–¹æ³• - session_id: {self.session_id}")
        super().close()
        logger.info(f"âœ… [Stream] RTCæµå…³é—­å®Œæˆ - session_id: {self.session_id}")
